{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "This notebook compares different topic modeling algorithms available in NBTM:\n",
    "\n",
    "| Model | Description | Key Feature |\n",
    "|-------|-------------|-------------|\n",
    "| **Gibbs LDA** | Collapsed Gibbs Sampling | Simple, interpretable |\n",
    "| **LDA-VI** | Variational Inference | Fast, scalable |\n",
    "| **HDP** | Hierarchical Dirichlet Process | Automatic topic count |\n",
    "| **CTM** | Correlated Topic Model | Topic correlations |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nbtm.models import create_model, get_available_models\n",
    "from nbtm.evaluation import (\n",
    "    compute_coherence,\n",
    "    compute_topic_diversity,\n",
    "    BenchmarkRunner,\n",
    ")\n",
    "from nbtm.visualization import (\n",
    "    plot_model_comparison,\n",
    "    plot_radar_comparison,\n",
    "    plot_training_time_comparison,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "\n",
    "Generate synthetic documents with known topic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topic vocabularies\n",
    "topic_words = {\n",
    "    \"tech\": [\"machine\", \"learning\", \"algorithm\", \"data\", \"model\", \"neural\", \"network\", \"deep\", \"training\", \"optimization\"],\n",
    "    \"science\": [\"research\", \"experiment\", \"hypothesis\", \"theory\", \"analysis\", \"evidence\", \"study\", \"method\", \"result\", \"conclusion\"],\n",
    "    \"stats\": [\"probability\", \"distribution\", \"bayesian\", \"inference\", \"prior\", \"posterior\", \"likelihood\", \"estimation\", \"variance\", \"mean\"],\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_document(topic_name, length=20):\n",
    "    \"\"\"Generate a document from a topic.\"\"\"\n",
    "    words = topic_words[topic_name]\n",
    "    return list(np.random.choice(words, size=length, replace=True))\n",
    "\n",
    "def generate_mixed_document(topics, weights, length=20):\n",
    "    \"\"\"Generate a document mixing multiple topics.\"\"\"\n",
    "    doc = []\n",
    "    for _ in range(length):\n",
    "        topic = np.random.choice(topics, p=weights)\n",
    "        word = np.random.choice(topic_words[topic])\n",
    "        doc.append(word)\n",
    "    return doc\n",
    "\n",
    "# Generate corpus\n",
    "documents = []\n",
    "topics = list(topic_words.keys())\n",
    "\n",
    "# Pure topic documents\n",
    "for topic in topics:\n",
    "    for _ in range(10):\n",
    "        documents.append(generate_document(topic))\n",
    "\n",
    "# Mixed topic documents\n",
    "for _ in range(20):\n",
    "    weights = np.random.dirichlet([0.5] * len(topics))\n",
    "    documents.append(generate_mixed_document(topics, weights))\n",
    "\n",
    "print(f\"Generated {len(documents)} documents\")\n",
    "print(f\"Sample document: {documents[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Models\n",
    "\n",
    "Create instances of each model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "model_configs = {\n",
    "    \"Gibbs LDA\": {\n",
    "        \"model_type\": \"lda_gibbs\",\n",
    "        \"num_topics\": 3,\n",
    "        \"alpha\": 0.1,\n",
    "        \"beta\": 0.01,\n",
    "    },\n",
    "    \"Variational LDA\": {\n",
    "        \"model_type\": \"lda_vi\",\n",
    "        \"num_topics\": 3,\n",
    "        \"alpha\": 0.1,\n",
    "        \"beta\": 0.01,\n",
    "    },\n",
    "    \"HDP\": {\n",
    "        \"model_type\": \"hdp\",\n",
    "        \"num_topics\": 10,  # Initial/max topics\n",
    "        \"alpha\": 1.0,\n",
    "        \"beta\": 0.01,\n",
    "    },\n",
    "    \"CTM\": {\n",
    "        \"model_type\": \"ctm\",\n",
    "        \"num_topics\": 3,\n",
    "        \"alpha\": 0.1,\n",
    "        \"beta\": 0.01,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Models to compare:\")\n",
    "for name in model_configs:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Evaluate\n",
    "\n",
    "Train each model and collect metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(\n",
    "        config[\"model_type\"],\n",
    "        num_topics=config[\"num_topics\"],\n",
    "        alpha=config[\"alpha\"],\n",
    "        beta=config[\"beta\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    # Train with timing\n",
    "    start_time = time.time()\n",
    "    model.fit(documents, num_iterations=300)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    coherence = compute_coherence(model, documents, measure=\"umass\")\n",
    "    diversity = compute_topic_diversity(model, top_n=10)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"model\": model,\n",
    "        \"training_time\": training_time,\n",
    "        \"coherence\": coherence,\n",
    "        \"diversity\": diversity,\n",
    "        \"num_topics\": model.num_topics,\n",
    "        \"log_likelihood\": model.log_likelihood(),\n",
    "    }\n",
    "    \n",
    "    print(f\"  Time: {training_time:.2f}s\")\n",
    "    print(f\"  Topics: {model.num_topics}\")\n",
    "    print(f\"  Coherence: {coherence:.4f}\")\n",
    "    print(f\"  Diversity: {diversity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Results\n",
    "\n",
    "Visualize the comparison between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"{'Model':<20} {'Topics':<10} {'Time (s)':<12} {'Coherence':<12} {'Diversity':<12}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"{name:<20} {res['num_topics']:<10} {res['training_time']:<12.2f} {res['coherence']:<12.4f} {res['diversity']:<12.4f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "models = list(results.keys())\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Training time\n",
    "times = [results[m][\"training_time\"] for m in models]\n",
    "axes[0].bar(x, times, color=\"steelblue\")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "axes[0].set_ylabel(\"Time (seconds)\")\n",
    "axes[0].set_title(\"Training Time\")\n",
    "\n",
    "# Coherence\n",
    "coherences = [results[m][\"coherence\"] for m in models]\n",
    "axes[1].bar(x, coherences, color=\"forestgreen\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "axes[1].set_ylabel(\"Coherence (UMass)\")\n",
    "axes[1].set_title(\"Topic Coherence\")\n",
    "\n",
    "# Diversity\n",
    "diversities = [results[m][\"diversity\"] for m in models]\n",
    "axes[2].bar(x, diversities, color=\"coral\")\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "axes[2].set_ylabel(\"Diversity\")\n",
    "axes[2].set_title(\"Topic Diversity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Topics\n",
    "\n",
    "Look at the topics learned by each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, res in results.items():\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"{name} Topics\")\n",
    "    print(\"=\" * 50)\n",
    "    res[\"model\"].print_topics(top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Selection Guidelines\n",
    "\n",
    "### When to use each model:\n",
    "\n",
    "| Model | Best For | Considerations |\n",
    "|-------|----------|----------------|\n",
    "| **Gibbs LDA** | Small-medium datasets, interpretability | Slower for large datasets |\n",
    "| **Variational LDA** | Large datasets, speed | May converge to local optima |\n",
    "| **HDP** | Unknown number of topics | Computationally expensive |\n",
    "| **CTM** | Correlated topics | More parameters to tune |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using BenchmarkRunner\n",
    "\n",
    "For more comprehensive benchmarking, use the `BenchmarkRunner` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BenchmarkRunner for systematic comparison\n",
    "runner = BenchmarkRunner(\n",
    "    models=[\"lda_gibbs\", \"lda_vi\"],\n",
    "    num_topics_range=[3, 5],\n",
    "    metrics=[\"coherence\", \"diversity\"],\n",
    ")\n",
    "\n",
    "benchmark_results = runner.run(documents, num_iterations=200)\n",
    "\n",
    "print(\"\\nBenchmark Results:\")\n",
    "for result in benchmark_results:\n",
    "    print(f\"  {result.model_name} (K={result.num_topics}): coherence={result.coherence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See `03_full_tutorial.ipynb` for a complete workflow with real data\n",
    "- Experiment with different hyperparameters (alpha, beta)\n",
    "- Try different numbers of topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
